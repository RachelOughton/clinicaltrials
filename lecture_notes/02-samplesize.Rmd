# Lecture 2 {-}

# Sample size {#rct-plan}

For most of this course, our trial will have two arms and our unit of randomization will be individual participants. In this section we'll focus on continuous primary outcome variables. 

\textit{Will go on to think about binary variables and time-to-event data.}

The topics we'll cover fall into two categories:
  
  * Before the trial - design and planning
  * After the trial - analysis and communication
  
but there is some interaction between these phases.

The first big question asked of a trial statistician is usually **how many participants does the trial need in order to be viable?**

\textit{Can also be asked about the design itself - lots of different sorts of trials. But not always!}

Broadly speaking, there are two (opposing) ethical issues  around sample size:
  
  1. Not enough particpants may mean not enough evidence to come to a conclusion. This is both scientifically disappointing and unethical. 
  \textit{To conduct the trial, some of the patients will have been subject to an inferior treatment (assuming one treatment was actually better), and if there is no conclusion then this was effectively for no purpose.}
  2. Too many patients \textit{(ie. we would be sufficiently likely to reach a conclusion with many fewer)} means subjecting more patients than necessary to an inferior treatment. \textit{Possibly also taken up more time and resources than was necessary.}

This has been quite woolly so far, but now we'll start to think more carefully.

## The treatment effect

\textit{In Section 1.3 we discussed the need to settle on a **primary outcome variable**. One reason this is important is that we base our sample size calculations on the primary outcome variable.}

We base our sample size calculations on the primary outcome variable.

:::{.definition}
Suppose our primary outcome variable is $X$, which has mean $\mu$ in the control group and mean $\mu + \tau$ in the treatment group. The variable $\tau$  is the **treatment effect**. The goal of our RCT is to learn about $\tau$. The larger $\tau$ is (in magnitude), the more pronounced the effect of the intervention.
:::

This problem is usually framed as a **hypothesis test**, where the null hypothesis is that $\tau=0$.

\textit{Before we can construct a method to calculate sample size, we need to think about what we'll do with the trial data once we have it, so we now have a brief-ish segue into hypothesis tests.}

## Reminder: hypothesis tests (with a focus on RCTs)

When performing a hypothesis test, what we are aiming to find is the **P-value**. 

:::{.definition}
The **P-value** is the probability of obtaining a result at least as extreme (ie. further away from the null hypothesis value) than the one obtained *given that the null hypothesis is true*.
:::

\textit{The p-value is the probability of obtaining whatever result (eg. treatment effect) we have have found simply by random chance, when in fact $H_0$ is true and there is no treatment effect (ie. $\tau=0$). Generally, a P-value of $\alpha = 0.05$ is accepted as sufficient evidence to reject the null hypothesis, although in clinical settings it can often be smaller (eg. $\alpha = 0.01$). It is conventional to present the P-value by simply saying whether it is smaller than some threshold (often 0.05), rather than giving the exact value. }

:::{.definition}
The threshold for the p-value below which the results are considered 'significant' is known as the **significance level** of the test, and is generally written $\alpha$. 
::: 

\textit{This use of a significance level is (in part) a legacy from early days when computers were rare and values were looked up in $t$-tables (or similar). Now that it is very simple to find the exact P-value, it is becoming more and more common to report the actual number. Indeed, there is a big difference between $p=0.049$ and $p=0.000049$.}

### Insignificant results

If our P-value is large, say 0.3 or 0.5, then our result is not at all unlikely under the null hypothesis, and provides no evidence to reject $H_0$. However, it is not inconsistent with the existence of a treatment effect, so we don't say there is evidence to accept $H_0$. 

\textit{If the true treatment effect $\tau$ were tiny, many trials would fail to find evidence to reject $H_0$. However, if our sample size were sufficiently large, we should be able to detect it. Conversely, if $\tau$ is very large, even a relatively small sample size is likely to provide enough evidence to reject $H_0$.}

A non-significant P-value means our results are consistent with $H_0:\; \tau=0$, and also with some small treatment effect. 

Key issue: what size of treatment effect do we care about? 

Our sample size should be big enough to be sufficiently likely to detect a clinically meaningful treatment effect.

\textit{We are being vague for now, but this is a key issue in determining an appropriate sample size.}

### One-sided or two-sided?

The trial clinicians will have strong beliefs about the direction of the treatment effect. Assuming that a larger value of the primary outcome variable $X$ is good, they will expect $\tau>0$ (or be prepared to accept $\tau=0$, no effect). 

Therefore should we perform a one-sided test, with

\begin{align*}
  H_0\,&:\, \tau=0\\
  H_1\,&:\, \tau>0?
\end{align*}

\textit{ANNOTATE PLOT: Suppose our test statistic $\sim t_{31}$ and we find $t-2$, as shown in plot. Then $p=1 - F_t\left(2, df=31\right)= 0.0272$ (where $F_t\left(\cdot\right)$ is the cumulative distribution function of the $t$ distribution) , and the result would be considered significant at the 0.05 level.}


```{r t31-onesided, echo=F, fig.cap = "The distribution $t_{31}$, with the area corresponding to $t > 2$ shaded."}
x2 = seq(2,4, by=0.01)
px2 = dt(x2, df=31)

ggplot(data=data.frame(x=c(-4,4)), aes(x)) +
         stat_function(fun=dt, args=list(df=31))+
  geom_ribbon(data=data.frame(x=x2, y=px2), aes(x=x, ymin=0, ymax=y), fill="red", alpha=0.4) + xlab("Test statistic (t)") + ylab("Density") + theme_bw()

```

If $t\gg{0}$, we obtain a small P-value, and reject $H_0$. Conclusion: the intervention is effective (in a good way). But what if we obtain $t\ll{0}$? In this one-sided set-up, there is no value of $t<0$ that would give a significant result. 

\textit{Negative values of $t$ are simply considered consistent with $H_0$, and there is no way to conclude that an intervention has a significantly negative effect.}

For this reason, we always conduct two sided hypothesis tests, with 

\begin{align*}
  H_0\,&:\, \tau=0\\
  H_1\,&:\, \tau\neq 0.
\end{align*}

\textit{ANNOTATE PLOT: Now values of $t$ with $t<-2$ are considered 'equivalent' to those with $t>2$, in the sense of how unlikely they are under $H_0$.}


```{r t31-twosided, echo=F, fig.cap = "The distribution $t_{31}$, with the area corresponding to $|t| > 2$ shaded."}
x2 =seq(2,4, by=0.01)
px2 = dt(x2, df=31)

x2a =seq(-4,-2, by=0.01)
px2a = dt(x2a, df=31)

ggplot(data=data.frame(x=c(-4,4)), aes(x)) +
         stat_function(fun=dt, args=list(df=31))+
  geom_ribbon(data=data.frame(x=x2, y=px2), aes(x=x, ymin=0, ymax=y), fill="red", alpha=0.4)+
  geom_ribbon(data=data.frame(x=x2a, y=px2a), aes(x=x, ymin=0, ymax=y), fill="red", alpha=0.4) + xlab("Test statistic (t)") + ylab("Density") + theme_bw()

```


The P-value for the two-sided test as shown in Figure \@ref(fig:t31-twosided) is 

$$ F\left(-2, df=31\right) + \left[1 - F\left(2, df=31\right)\right] = 2\times{0.0272} = 0.0543$$
and the result is no longer significant at the 0.05 level. Throughout this course, we will always use two-tailed tests.

## Constructing a measure of effect size {#sec-measDcont}

Let's say we are recruiting participants into two groups: group $T$ will be given the new treatment (we call them the *treatment group* or *treatment arm*) and group $C$ will be given the control (they are the *control group* or *control arm*). 

\textit{Talk about blinding - should really have A and B, and statistician not know which is T and C. This is for simplicity and clarity.}

Suppose we have $n$ patients in group $C$, and $m$ in group $T$, and

\begin{align*}
X & \sim N\left(\mu, \sigma^2\right) \text{ in group }C\\
X & \sim N\left(\mu + \tau, \sigma^2\right) \text{ in group }T.
\end{align*}

\textit{The primary outcome variable $X$ is normally distributed with mean $\mu$ in group C (the control group) and mean $\mu+\tau$ in group T (the intervention group), and common standard deviation $\sigma$. We will use $X$ for the primary outcome variable}

We are testing the null hypothesis $H_0: \tau=0$ against the alternative hypothesis $H_1: \tau\neq{0}$. 

Using the trial data we find sample means $\bar{x}_C$ and $\bar{x}_T$ from each group, and a pooled estimate of the standard deviation 

$$ s = \sqrt{\frac{\left(n-1\right)s_C^2 + (m-1)s_T^2}{n+m - 2}},
$$
where $s_C$ and $s_T$ are the sample standard deviations for groups $C$ and $T$ respectively, eg

$$
s_C = \sqrt{\frac{\sum\limits_{i=1}^n{\left(x_i - \bar{x}_C\right)^2}}{n-1}}.
$$

Using these values we can compute 

$$D = \frac{\bar{x}_T - \bar{x}_C}{s\sqrt{\frac{1}{n} + \frac{1}{m}}}$$
as a standardised measure of the effect $\tau$.

::: {.theorem}

Under $H_0$, $D$ has a $t$-distribution with $n+m-2$ degrees of freedom.

:::


:::{.proof}

Under $H_0$ the $x_i$ are iid $N\left(\mu,\;\sigma^2\right)$, and so

\begin{align*}
\bar{x}_C & \sim{N\left(\mu, \frac{\sigma^2}{n}\right)}\\
\bar{x}_T & \sim{N\left(\mu, \frac{\sigma^2}{m}\right)}
\end{align*}

and therefore

$$
\bar{x}_T - \bar{x}_C \sim{N \left(0, \sigma^2\left[\frac{1}{n} + \frac{1}{m}\right] \right)}$$

and
$$
\frac{\bar{x}_T - \bar{x}_C}{\sigma \sqrt{\frac{1}{n}+\frac{1}{m}}} \sim{N\left(0,1\right)}.$$

We know that for $x_1,\ldots,x_n,\sim N\left(\mu,\sigma^2\right)$ for some arbitrary $\mu$ and $\sigma^2$, 

$$\frac{1}{\sigma^2}\sum\limits_{i=1}^n\left(x_i - \bar{x}\right)^2 \sim{\chi^2_{n-1}},$$
and so we have 

\begin{align*}
\frac{n-1}{\sigma^2}s_C^2 & \sim \chi^2_{n-1}\\
\frac{m-1}{\sigma^2}s_T^2 & \sim \chi^2_{m-1}\\
\text{and} &\\
\frac{1}{\sigma^2}\left[\left(n-1\right)s_C^2 + \left(m-1\right)s_T^2\right] & = \frac{n+m-2}{\sigma^2}s^2\\
&\sim \chi^2_{n+m-2}.
\end{align*}

The definition of a $t$-distribution is that if $Z\sim N\left(0,1\right)$ and $Y \sim{\chi^2_n}$ then

$$X = \frac{Z} {\sqrt{\frac{Y}{n}}} \sim{t_n},$$
that is $X$ has a $t$ distribution with $n$ degrees of freedom.

Plugging in our $N\left(0,1\right)$ variable for $Z$ and our $\chi^2_{n+m-2}$ variable for $Y$, we have

\begin{align*}
\frac{\frac{\bar{x}_T - \bar{x}_C}{\sigma\sqrt{\frac{1}{n} + \frac{1}{m}}}}{\sqrt{\left(\frac{n+m-2}{\sigma^2}s^2\right) \bigg/ \left(n+m-2\right)}} & = \frac{\bar{x}_T - \bar{x}_C}{\sigma\sqrt{\frac{1}{n} + \frac{1}{m}}} \bigg/ \frac{s}{\sigma} \\
& = \frac{\bar{x}_T - \bar{x}_C}{s\sqrt{\frac{1}{n} + \frac{1}{m}}} \\
& = D
\end{align*}

and therefore $D$ has a $t$ distribution with $n+m-2$ degrees of freedom.


:::

We can therefore use $D$ as our test statistic; if $D$ is such that 

$$ |D| > t_{n+m-2}\left(\alpha/2\right)$$
where 
$t_{n+m-2}\left(\cdot\right)$ is the function such that  $P\left(T>t_{df}\left(\xi\right)\right) = \xi$ when $T \sim{t_{df}}$ then we can reject $H_0$.

Generally we approximate this with a normal distribution (since $n$ and $m$ are usually sufficiently large).

So, if we have run a trial, and have obtained $n$ values of $X$ from group $C$ and $m$ values of $X$ from group $T$, we can compute $D$. If $D$ lies outside the interval $\left[-z_{\alpha/2}, z_{\alpha/2}\right]$ then we reject $H_0$. 

This is equivalent to $\bar{x}_T - \bar{x}_C$ falling outside the interval

$$\left[-z_{\alpha/2}s\sqrt{\frac{1}{n} + \frac{1}{m}}, z_{\alpha/2}s\sqrt{\frac{1}{n} + \frac{1}{m}}  \right]. $$

### Brief aside on notation {-}

We'll see a lot of the notation $z_{\alpha/2}$ and similar, so to clarify:

```{r}
x2 = seq(1.96,3, by=0.01)
px2 = dnorm(x2)

ggplot(data=data.frame(x=c(-3,3)), aes(x)) +
         stat_function(fun=dnorm, args=list(mean=0, sd=1))+
  geom_ribbon(data=data.frame(x=x2, y=px2), aes(x=x, ymin=0, ymax=y), fill="red", alpha=0.4) + xlab("Test statistic") + ylab("Density") +
    annotate(geom = "text", x=0, y=0.15, label = expression(Phi(z[alpha/2])))+
   scale_x_continuous(breaks=c(0, 1.96), label = c(0, expression(z[alpha/2])), limits = c(-5,5)) + theme_bw()

```
\textit{In R, we have $\Phi\left(z_{\alpha/2}\right) = \texttt{pnorm}\left(z_{\alpha/2}\right)$ and $z_{\alpha/2} = \texttt{qnorm}\left(\Phi\left(z_{\alpha/2}\right)\right)$. `qnorm` is the quantile and `pnorm` is the cumulative distribution function.} 

\textit{We have constructed our whole argument under the assumption that $H_0$ is true, and that the probability of such a value is therefore $\alpha$. We want this probability to be small, since it constitutes an error; $H_0$ is true, but our value of $D$ (or the difference in means) leads us to reject $H_0$. This is sometimes called the 'type I' error rate. But what if $H_0$ is false?}

Our argument is based on $H_0$ being true - but what if it isn't?

# Lecture 3 {-}

Recap: 

  * We constructed a measure $D = \frac{\bar{x}_T - \bar{x}_C}{s\sqrt{\frac{1}{n} + \frac{1}{m}}}$ that we can use to test $H_0:\; \tau=0$, since $D\sim{t_{n+m-2}}$ (and approximately $D\sim N\left(0,1\right)$).

## Power: If $H_0$ is false {#sec-power}

So far, if $H_0$ is true, we have a small probability of rejecting $H_0$ (type I error rate). 

Flip side: if $H_0$ is false, and $\tau\neq{0}$, we want a high probability of rejecting $H_0$.

::: {.definition}
The **power** of a test is the probability that we reject $H_0$, given that $H_0$ is false. The **power function** depends on the value of $\tau$ and is

$$\Psi\left(\tau\right) = \Pr\left(\text{Reject } H_0\mid{\tau\neq{0}}\right) = 1 - \beta.$$
The quantity $\beta$ therefore represents $\Pr\left(\text{Accept } H_0\mid{\tau\neq{0}}\right)$, which is the **type II error rate**.
:::


\textit{If you find the notation confusing (as I do!) then it might be helpful to remember that both $\alpha$ and $\beta$ are \textbf{error rates} - probabilities of coming to the wrong conclusion. It is common to talk in terms of $\alpha$, the significance level, (which will be a low number, often 0.05) and of $1-\beta$, the power (which will be a high number, often 0.8). I've found though that it is not uncommon to find people refer to $\beta$ (rather than $1-\beta$) as the power. If in doubt, keep in mind that we require $\alpha,\;\beta \ll 0.5$. It is also common to use percentages: a significance level of $\alpha=0.05$ can also be referred to as "the 95% level", and $\beta=0.2$ is the same as a "power of 80%". When using percentages, we talk in terms of the amount of time we expect the test to come to the correct conclusion.}

\textit{If you notice any mistakes in these notes along these (or other!) lines, please point them out.}


Under $H_1$, we have (approximately)

$$D \sim{N\left(\frac{\tau}{\sigma\lambda\left(n,m\right)}, 1\right)},$$
where $\lambda\left(n,m\right) = \sqrt{\frac{1}{n}+\frac{1}{m}}$ and 
$$D = \frac{\bar{x}_T - \bar{x}_C}{s\lambda\left(n,m\right)}.$$

Figure \@ref(fig:accepth0) shows the distribution of $D$ under $H_0$ and $H_1$ for some arbitrary (non-zero) effect size $\tau$. The turquoise bar shows the acceptance region of $H_0$, ie. the range of observed values of $D$ for which we will fail to reject $H_0$. We see that this contains 95% of the area of the $H_0$ distribution (we have set $\alpha = 0.05$ here), so under $H_0$, we have a 0.95 probability of observing a value of $D$ that is consistent with $H_0$. 

```{r accepth0, echo=F, fig.cap = "The distribution of $D$ under both $H_0$ and $H_1$ for some arbitrary values of treatment effect, population variance, $n$ and $m$, with the region in which we fail to reject $H_0$ shown by the turquoise bar and the red shading."}
tau = 2
xvec = seq(-1,qnorm(0.975), length=100)
## This needs x axis labels changing
## box for acceptance region of H_0
## labels for which distribution is which
## no y axis labels / ticks

ggplot() +  stat_function(fun=dnorm) + 
  stat_function(fun=dnorm, args = list(mean=3), lty=2)+
  xlab("D") +
  geom_ribbon(data=data.frame(x=xvec, y=dnorm(xvec, mean=3)), aes(x=x, ymin=0, ymax=y), fill="red", alpha=0.4)+
  geom_rect(data=NULL, aes(
    xmin=-qnorm(0.975), 
    xmax = qnorm(0.975),
    ymin=0.01,
    ymax=0.03),
    fill = "darkturquoise",
    alpha=0.4,
    col = 1)+
  annotate(geom  = "text", x=0, y=0.045, label = expression('Fail to reject H'[0])) +
  annotate(geom= "text", x=c(-2.5, 5), y=c(0.35,0.35), label = c(expression('Distribution under H'[0]), expression('Distribution under H'[1]))) +
  geom_segment(aes(x=3, xend=3, y=0, yend=0.5), lty=2) +
    geom_segment(aes(x=qnorm(0.975), xend=qnorm(0.975), y=0, yend=-0.01), lty=1)+
  geom_segment(aes(x=-qnorm(0.975), xend=-qnorm(0.975), y=0, yend=-0.01), lty=1)+
  geom_segment(aes(x=3, xend=3, y=0, yend=-0.01), lty=1)+

  scale_x_continuous(breaks=c(-qnorm(0.975), 0, qnorm(0.975), 3), label = c(expression(-z[alpha/2]), 0, expression(z[alpha/2]), expression(tau/(sigma*lambda))), limits = c(-5,8)) + theme_bw()


```

However, if $H_1$ is true, and $\tau\neq{0}$, there is a non-zero probability of observing a value of $D$ that would lead us to fail to reject $H_0$. This is shown by the area shaded in red, and it has area $\beta$. One minus this area (ie. the area under $H_1$ that leads us to accept $H_1$) is the power, $1-\beta$. 

\textit{We can see that if the distributions have better separation, as in Figure 2.3, the power becomes greater. This can be as a result of a larger $\tau$, a smaller $\sigma$ or a smaller $\lambda$ (therefore larger $m$ and/or $n$).}

[FIGURE!!]

```{r accepth0-1, echo=F, fig.cap = "The distribution of D under both $H_0$ and $H_1$ for some arbitrary values of effect size, population variance, $n$ and $m$, with the region in which we fail to reject $H_0$ shown by the turquoise bar and the red shading."}

xvec = seq(-1,qnorm(0.975), length=100)
## This needs x axis labels changing
## box for acceptance region of H_0
## labels for which distribution is which
## no y axis labels / ticks

ggplot() +  stat_function(fun=dnorm) + 
  stat_function(fun=dnorm, args = list(mean=4), lty=2)+
  xlab("D") +
  geom_ribbon(data=data.frame(x=xvec, y=dnorm(xvec, mean=4)), aes(x=x, ymin=0, ymax=y), fill="red", alpha=0.4)+
  geom_rect(data=NULL, aes(
    xmin=-qnorm(0.975), 
    xmax = qnorm(0.975),
    ymin=0.01,
    ymax=0.03),
    fill = "darkturquoise",
    alpha=0.4,
    col = 1)+
  annotate(geom  = "text", x=0, y=0.045, label = expression('Fail to reject H'[0])) +
  annotate(geom= "text", x=c(-2.5, 6), y=c(0.35,0.35), label = c(expression('Distribution under H'[0]), expression('Distribution under H'[1]))) +
  geom_segment(aes(x=4, xend=4, y=0, yend=0.5), lty=2) +
  geom_segment(aes(x=qnorm(0.975), xend=qnorm(0.975), y=0, yend=-0.01), lty=1)+
  geom_segment(aes(x=-qnorm(0.975), xend=-qnorm(0.975), y=0, yend=-0.01), lty=1)+
  geom_segment(aes(x=4, xend=4, y=0, yend=-0.01), lty=1)+
  scale_x_continuous(breaks=c(-qnorm(0.975), 0, qnorm(0.975), 4), label = c(expression(-z[alpha/2]), 0, expression(z[alpha/2]), expression(tau/(sigma*lambda))), limits = c(-5,9))  + theme_bw()

```


For given values of $\alpha$, $\sigma$ and $\lambda\left(n,m\right)$, we can calculate the power function in terms of $\tau$ by finding the area of the distribution of $D$ under $H_1$ for which we accept $H_1$.

\begin{equation}
\Psi\left(\tau\right) = 1-\beta = \left[1 - \operatorname{\Phi}\left(z_{\frac{\alpha}{2}} - \frac{\tau}{\sigma\lambda}\right)\right] + \operatorname{\Phi}\left(-z_{\frac{\alpha}{2}} - \frac{\tau}{\sigma\lambda}\right)
(\#eq:powerfun)
\end{equation}

The first term in Equation \@ref(eq:powerfun) is the area in the direction of $\tau$. In Figures \@ref(fig:accepth0) and \@ref(fig:accepth0-1) this is the region to the right of the interval for which we fail to reject $H_0$, ie. where $$D > z_{\frac{\alpha}{2}}.$$

The second term in Equation \@ref(eq:powerfun) represents the area away from the direction of $\tau$, ie. a value of $D$ such that 

$$ D < - z_{\frac{\alpha}{2}},$$
assuming without loss of generality that $\tau>0$. 

\textit{Figure \@ref(fig:powercurve) shows the power function $\Psi\left(\tau\right)$ for $\tau$ in units of $\sigma$ (or you could think of this as for $\sigma=1$), for three different pairs of values of $n$ and $m$ (remember that these enter the power function via $\lambda$) with $\alpha=0.05$. We see that in general the power is higher for larger sample sizes, and that of the two designs where $n+m=200$, the balanced one with $n=m=100$ achieves the greatest power. }

  * Larger sample size $\rightarrow$ greater power
  * Equal groups $\rightarrow$ greater power

In general, the probability of rejecting $H_0$ increases as $\tau$ moves away from zero.

Notice also that all the curves pass through the point $\tau=0,\,\beta=0.05$. Since $\tau=0$ corresponds to $H_0$ being true, it makes sense that the probability of rejecting the $H_0$ is the significance level $\alpha$.


```{r powercurve, fig.cap = "Power curves for various values of $n$ and $m$, with effect size in units of standard deviation, given a type I error rate of 0.05.", fig.width = 8, fig.height=4}

tauvec = seq(-1.5, 1.5, length=100)

lambdafun = function(n, m){
  sqrt((1/n) + (1/m))
}

powerfun = function(tau, n, m){
  term1 = 1 - pnorm(qnorm(0.975) - tau/lambdafun(n,m))
  term2 = pnorm(-qnorm(0.975) - tau/lambdafun(n,m))
  term1 + term2
}

df_15_15 = data.frame(
  tau=tauvec,
  power = powerfun(tauvec, 15, 15),
  SampleSize = rep("n=15, m=15", 100)
  )
df_100_100 = data.frame(
  tau=tauvec,
  power = powerfun(tauvec, 100, 100),
  SampleSize = rep("n=100, m=100", 100)
  )
df_20_180 = data.frame(
  tau = tauvec,
  power = powerfun(tauvec, 20, 180),
  SampleSize = rep("n=20, m=180", 100)
)
df_67_133 = data.frame(
  tau = tauvec,
  power = powerfun(tauvec, 67, 133),
  SampleSize = rep("n=67, m=133", 100)
)

df_full = rbind(df_15_15, df_100_100, df_67_133, df_20_180)

df_full$SampleSize = as.factor(df_full$SampleSize)

ggplot(data=df_full, aes(x=tau, y=power, col = SampleSize, lty=SampleSize)) + 
  geom_path() + xlim(-1.5, 1.5) +
  xlab(expression(tau*' in units of '*sigma))+
  annotate(geom="text", x=c(-1,-0.75, -0.6, -0.25), y=c(0.62, 0.8, 0.95, 0.9),
           label = parse(text = paste(expression(lambda*"="),  round(c(lambdafun(15,15), lambdafun(20,180), lambdafun(67,133), lambdafun(100,100)),3), sep = '*'))) + theme_bw()


```
 
It is common to think of the effect size in units of $\sigma$, as we have done here. 

\textit{This makes results more intuitive, since we don't need to have a good knowledge of the actual outcome variable to know what is a small or large effect size. It is also helpful in situations where the population standard deviation is not well understood, since the trial can be planned with this sort of effect size in mind. To denote the effect size in units of $\sigma$, we will write $\tau_\sigma$, although in practice it is more usual to give both the same notation.}

## A sample size formula {#sec-ssformulacont}

Equation \@ref(eq:powerfun) allows us to find any one of $\tau_\sigma,\,\alpha,\,\beta$ and $\lambda\left(n,m\right)$ given values for the others. 

\begin{equation}
\Psi\left(\tau\right) = 1-\beta = \left[1 - \operatorname{\Phi}\left(z_{\frac{\alpha}{2}} - \frac{\tau}{\sigma\lambda}\right)\right] + \operatorname{\Phi}\left(-z_{\frac{\alpha}{2}} - \frac{\tau}{\sigma\lambda}\right)
\end{equation}

Values for $\alpha$ and $\beta$ are often specified by those planning the trial as around $\alpha \in \left[0.01,0.05\right],\,1-\beta\in\left[0.8,0.9\right]$.

The remaining two variables, $\tau_\sigma$ and $\lambda\left(n,m\right)$ are generally settled using one or both of the following questions:
  
  * Given our budget constraints, and their implications for $n$ and $m$, what is the smallest value of $\tau_\sigma$ we can achieve?
  * What is the smallest value of $\tau_\sigma$ that would be clinically useful to detect, and what value of $\lambda\left(n,m\right)$ do we need in order to achieve it?
  
  In a medical setting, an estimate of $\sigma$ is usually available, and so we will return to thinking in terms of $\tau$ and $\sigma$. In this equation, the value we use (or find) for $\tau$ is the **minimum detectable effect size**, which we will denote $\tau_M$.

:::{.definition}
The **minimum detectable effect size** $\tau_M$ for a particular trial is the smallest value of effect size that is able to be detected with power $1-\beta$ and at significance level $\alpha$ (for some specified values of $\alpha,\;\beta$).
:::
  
\textit{Note that we will not *definitely* detect an effect of size $\tau_M$, if it exists; by construction, we will detect it with probability $1-\beta$. If $|\tau| > |\tau_M|$ (ie. the true effect size is further from zero than $\tau_M$ is) then the probability of detecting it will be greater than $1-\beta$. If $|\tau| < |\tau_M|$ then the probability of detecting it will be less than $1-\beta$.}

\textit{Although we could solve Equation \@ref(eq:powerfun) numerically, in practice we use an approximation. The second term, representing observed values of $D$ that are far enough away from 0 *in the opposite direction from the true $\tau$* to lead us to reject $H_0$ is so negligible as to be able to be discounted entirely. Indeed, if we were to observe such a value of $D$, we would come to the wrong conclusion about $\tau$.}

Therefore, Equation \@ref(eq:powerfun) becomes

\begin{equation}
\Psi\left(\tau\right) = 1-\beta = \left[1 - \operatorname{\Phi}\left(z_{\frac{\alpha}{2}} - \frac{\tau_M}{\sigma\lambda}\right)\right].
(\#eq:powerfun2)
\end{equation}
  
  Because $\operatorname{\Phi}\left(z_\beta\right) = 1 - \beta$ (by definition) and $\operatorname{\Phi}\left(-z\right) = 1 - \operatorname{\Phi}\left(z\right)$ we can write this as
  
  $$ \operatorname{\Phi}\left(z_\beta\right) = \operatorname{\Phi}\left(\frac{\tau_M}{\sigma\lambda} - z_{\frac{\alpha}{2}}\right), $$
    where $\tau_M$ is our minimum detectable effect size. Because of the monotonicity of $\operatorname{\Phi}\left(\cdot\right)$, we can write
  
\begin{equation}
\begin{aligned}
  z_\beta & = \frac{\tau_M}{\sigma\lambda} - z_{\frac{\alpha}{2}} \\
  z_\beta + z_{\frac{\alpha}{2}} & = \frac{\tau_M}{\sigma\lambda}.
  (\#eq:powerfun3)
  \end{aligned}
\end{equation}
    
Because we want to think about sample sizes, we rewrite this further. It is most common to perform trials with $n=m=N$ participants in each group, in which case
    
$$ \lambda\left(n,m\right) = \sqrt{\frac{2}{N}}$$
      
and Equation \@ref(eq:powerfun3) rearranges to
    
\begin{equation}
    N = \frac{2\sigma^2\left(z_\beta + z_{\frac{\alpha}{2}}\right)^2}{\tau_M^2}.
    (\#eq:sscont)
\end{equation}
      
:::{.example}
[from @zhong2009calculate]
    A trial is being planned to test whether there is a difference in the efficacy of ACEII antagonist (a new drug) and ACE inhibitor (the standard drug) for the treatment of primary hypertension (high blood pressure). The primary outcome variable is change in sitting diastolic blood pressure (SDBP, mmHg) compared to a baseline measurement taken at the start of the trial. The trial should have a significance level of $\alpha=0.05$ and a power of $1-\beta = 0.8$, with the same number of participants in each group. The minimum clinically important difference is $\tau_M = 3 \text{ mmHg}$ and the pooled standard deviation is $s = 8 \text{ mmHg}$. Therefore, using equation \@ref(eq:sscont) the sample size should be at least
      
\begin{align*}
      N & = \frac{2\times{8}^2\left(0.842 + 1.96\right)^2}{3^2}\\
      & = 111.6,
\end{align*}
      
and therefore we need at least 112 participants in each trial arm.
:::
        

